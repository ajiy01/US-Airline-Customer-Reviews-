{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airlines Insights\n",
    "\n",
    "---\n",
    "\n",
    "## Web scraping and analysis\n",
    "\n",
    "This Jupyter notebook includes some code to get you started with web scraping. We will use a package called `BeautifulSoup` to collect the data from the web. Data was collected and saved it into a local `.csv` file for starting the analysis.\n",
    "\n",
    "### Scraping data from Skytrax\n",
    "\n",
    "Visited [https://www.airlinequality.com]. For this task, we are only interested in reviews related to British Airways and the Airline itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_url = \"https://www.airlinequality.com/airline-reviews/alaska-airlines\"\n",
    "pages = 50\n",
    "page_size = 100\n",
    "\n",
    "reviews = []\n",
    "traveller = []\n",
    "labels_star = []\n",
    "\n",
    "\n",
    "# for i in range(1, pages + 1):\n",
    "for i in range(1, pages + 1):\n",
    "\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse content\n",
    "    content = response.content\n",
    "    parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "    # Reviews\n",
    "    for para in parsed_content.find_all(\"div\", {\"class\": \"text_content\"}):\n",
    "        reviews.append(para.get_text())\n",
    "        \n",
    "    # Travel Stats\n",
    "    for stats in parsed_content.find_all(\"div\", {\"class\": \"review-stats\"}):\n",
    "        # Extract text content from the stats element\n",
    "        stats_text = stats.get_text()\n",
    "    \n",
    "        # Regular expression patterns for each category\n",
    "        regex_categories = {'Type Of Traveller': r'Type Of Traveller(.+)',\n",
    "                            'Seat Type': r'Seat Type(.+)',\n",
    "                            'Route': r'Route(.+)',\n",
    "                            'Date Flown': r'Date Flown(.+)',\n",
    "                            'Seat Comfort': r'Seat Comfort(\\d+)',\n",
    "                            'Cabin Staff Service': r'Cabin Staff Service(\\d+)',\n",
    "                            'Food & Beverages': r'Food & Beverages(\\d+)',\n",
    "                            'Inflight Entertainment': r'Inflight Entertainment(\\d+)',\n",
    "                            'Ground Service': r'Ground Service(\\d+)',\n",
    "                            'Wifi & Connectivity': r'Wifi & Connectivity(\\d+)',\n",
    "                            'Value For Money': r'Value For Money(\\d+)',\n",
    "                            'Recommended': r'Recommended(.+)'\n",
    "                            }\n",
    "\n",
    "        # Extract results using regular expressions\n",
    "        results = {}\n",
    "        for category, regex_pattern in regex_categories.items():\n",
    "            match = re.search(regex_pattern, stats_text)\n",
    "            if match:\n",
    "                results[category] = match.group(1).strip()\n",
    "                \n",
    "        res = {}\n",
    "        # Append results to the traveller list\n",
    "        for category, value in results.items():\n",
    "            res = f\"{category}: {value}\"\n",
    "            traveller.append(res)\n",
    "    \n",
    "    print(f\"   ---> {len(reviews)} total reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dicts = []\n",
    "\n",
    "# Iterate over each set of category-value pairs\n",
    "for i in range(0, len(traveller), 5):  # Assuming there are 11 categories per review\n",
    "    data_dict = {}\n",
    "    for j in range(5):  # 11 categories per review\n",
    "        index = i + j\n",
    "        if index < len(traveller):  # Check if the index is within the range of the list\n",
    "            key, value = traveller[index].split(': ')\n",
    "            data_dict[key] = value\n",
    "    data_dicts.append(data_dict)\n",
    "    \n",
    "df_traveller = pd.DataFrame(data_dicts)\n",
    "df_traveller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"Reviews\"] = reviews\n",
    "df = df.merge(df_traveller, how='left', left_index=True, right_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Assuming 'df' is your DataFrame containing the data\n",
    "df.to_csv(f\"alaska-airlines/AlaskaAirlinesReviews{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.CSV\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f7924c4c56b083e0e50eadfe7ef592a7a8ef70df33a0047f82280e6be1afe15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
